# âœ… Stage 4-1 ì™„ë£Œ: OpenAI API ê³µí†µ í—¬í¼ ëª¨ë“ˆ

## ğŸ“‹ **[ìš”ì²­ 1] ì„¤ê³„ ê²°ì •** âœ…

### í´ë¼ì´ì–¸íŠ¸ ì„ íƒ: OpenAI ê³µì‹ SDK

**ì„ íƒ ì´ìœ :**
1. âœ… íƒ€ì… ì•ˆì •ì„± (TypeScript ë‚´ì¥)
2. âœ… í‘œì¤€ ë°©ë²• (OpenAI ê³µì‹ ê¶Œì¥)
3. âœ… ìë™ ì¬ì‹œë„ (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì²˜ë¦¬)
4. âœ… ìŠ¤íŠ¸ë¦¬ë° ì§€ì› (í–¥í›„ í™•ì¥)
5. âœ… ê³µì‹ ìœ ì§€ë³´ìˆ˜

**ë¹„êµ:**

| í•­ëª© | OpenAI SDK | fetch (ì§ì ‘) |
|------|-----------|-------------|
| íƒ€ì… ì•ˆì •ì„± | âœ… ë‚´ì¥ | âŒ ìˆ˜ë™ |
| ì—ëŸ¬ ì²˜ë¦¬ | âœ… ìë™ | âŒ ìˆ˜ë™ |
| ì¬ì‹œë„ ë¡œì§ | âœ… ë‚´ì¥ | âŒ ìˆ˜ë™ |
| ìŠ¤íŠ¸ë¦¬ë° | âœ… ê°„ë‹¨ | âŒ ë³µì¡ |
| ìœ ì§€ë³´ìˆ˜ | âœ… ê³µì‹ | âŒ ì§ì ‘ |

**ê²°ë¡ :** OpenAI SDK = **ì•ˆì „í•˜ê³  í‘œì¤€ì **

---

### íŒŒì¼ êµ¬ì¡°

```
lib/ai/
â”œâ”€â”€ types.ts       # AI íƒ€ì… ì •ì˜
â”œâ”€â”€ openai.ts      # OpenAI í´ë¼ì´ì–¸íŠ¸ + ê³µí†µ ë©”ì„œë“œ
â”œâ”€â”€ prompts.ts     # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â””â”€â”€ index.ts       # í†µí•© export
```

---

## ğŸ› ï¸ **[ìš”ì²­ 2] ì½”ë“œ êµ¬í˜„** âœ…

### 1. types.ts (íƒ€ì… ì •ì˜)

**ì£¼ìš” íƒ€ì…:**

```typescript
// ìš”ì²­
- TextModelParams
- VisionModelParams

// ì‘ë‹µ
- AIResponse (content, usage, model, finishReason)
- AIResult<T> (ì„±ê³µ/ì‹¤íŒ¨ Result íƒ€ì…)

// í”„ë¡¬í”„íŠ¸ íŒŒë¼ë¯¸í„°
- QuestionExplanationParams
- WeaknessAnalysisParams
- ExamParsingParams
```

**Result íŒ¨í„´:**
```typescript
type AIResult<T> = 
  | { success: true; data: T }
  | { success: false; error: string; code?: string };
```

---

### 2. openai.ts (í•µì‹¬ ë¡œì§)

**ê¸°ëŠ¥:**

#### A. í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤
```typescript
let openaiClient: OpenAI | null = null;

function getOpenAIClient(): OpenAI {
  if (!openaiClient) {
    openaiClient = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }
  return openaiClient;
}
```

#### B. callTextModel
```typescript
export async function callTextModel(
  params: TextModelParams
): Promise<AIResult<AIResponse>> {
  try {
    const client = getOpenAIClient();
    const model = params.model || getTextModel();

    const response = await client.chat.completions.create({
      model,
      messages: [
        { role: 'system', content: params.systemPrompt },
        { role: 'user', content: params.userPrompt },
      ],
      temperature: params.temperature ?? 0.7,
      max_tokens: params.maxTokens ?? 2000,
    });

    return { success: true, data: { content, usage, model, finishReason } };
  } catch (error) {
    return { success: false, error: errorMessage, code: errorCode };
  }
}
```

#### C. callVisionModel
```typescript
export async function callVisionModel(
  params: VisionModelParams
): Promise<AIResult<AIResponse>> {
  // imageUrl or imageBase64 ë°›ìŒ
  // image_url content typeìœ¼ë¡œ ì „ì†¡
  // ë‚˜ë¨¸ì§€ ë¡œì§ì€ callTextModelê³¼ ë™ì¼
}
```

**ì—ëŸ¬ ì²˜ë¦¬:**
- âœ… OpenAI ì—ëŸ¬ ì½”ë“œ ì¶”ì¶œ
- âœ… ì½˜ì†” ë¡œê·¸
- âœ… Result íƒ€ì… ë°˜í™˜ (throw ì•ˆ í•¨)

---

### 3. prompts.ts (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿)

**êµ¬í˜„ëœ í”„ë¡¬í”„íŠ¸ 3ê°œ:**

#### A. buildQuestionExplanationPrompt
```typescript
// ì…ë ¥: questionType, questionText, choices, correctAnswer, studentAnswer, isCorrect
// ì¶œë ¥: { systemPrompt, userPrompt }

systemPrompt:
- ì˜ì–´ ë¬¸ì œ í•´ì„¤ ì „ë¬¸ê°€
- ëª…í™•í•˜ê³  ì¹œì ˆí•œ í•œêµ­ì–´
- êµ¬ì¡°: ì •ë‹µ í™•ì¸ â†’ í•µì‹¬ ê°œë… â†’ ì˜¤ë‹µ ë¶„ì„ â†’ íŒ

userPrompt:
- ë¬¸ì œ + ë³´ê¸° + ì •ë‹µ + í•™ìƒ ë‹µ + ì±„ì  ê²°ê³¼
- í‹€ë¦° ê²½ìš° ì§‘ì¤‘ ì„¤ëª… ìš”ì²­
```

#### B. buildWeaknessAnalysisPrompt
```typescript
// ì…ë ¥: examTitle, totalQuestions, correctCount, wrongCount, wrongQuestions
// ì¶œë ¥: { systemPrompt, userPrompt }

systemPrompt:
- êµìœ¡ ì „ë¬¸ê°€
- ì•½ì  íŒŒì•… + ê°œì„  ë°©í–¥
- êµ¬ì¡°: ì„±ì  ìš”ì•½ â†’ ì•½ì  ë¶„ì„ â†’ ì‹¤ìˆ˜ íŒ¨í„´ â†’ ê°œì„  ë°©í–¥

userPrompt:
- ì‹œí—˜ ì •ë³´ + ì˜¤ë‹µ ìƒì„¸ (ë¶„ì•¼, ë‚œì´ë„ í¬í•¨)
- 4ê°€ì§€ ë¶„ì„ ìš”ì²­ (ì•½ì , íŒ¨í„´, í•™ìŠµ ì „ëµ)
```

#### C. buildExamParsingPrompt
```typescript
// ì…ë ¥: examType, language
// ì¶œë ¥: { systemPrompt, userPrompt }

systemPrompt:
- ì‹œí—˜ ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ê°€
- JSON í˜•ì‹ ì¶œë ¥

userPrompt:
- ìœ í˜• + ì–¸ì–´ ëª…ì‹œ
- JSON ìŠ¤í‚¤ë§ˆ ì œê³µ
- ì¸ì‹ ë¶ˆëª…í™• ì‹œ "UNCLEAR" í‘œì‹œ
```

---

### 4. index.ts (í†µí•© Export)

```typescript
// OpenAI í´ë¼ì´ì–¸íŠ¸
export { callTextModel, callVisionModel } from './openai';

// í”„ë¡¬í”„íŠ¸ ë¹Œë”
export { buildQuestionExplanationPrompt, ... } from './prompts';

// íƒ€ì…
export type { TextModelParams, AIResponse, AIResult, ... } from './types';
```

---

### 5. í™˜ê²½ ë³€ìˆ˜

```.env.example
OPENAI_API_KEY=sk-...
OPENAI_MODEL_TEXT=gpt-4o-mini
OPENAI_MODEL_VISION=gpt-4o
```

---

## ğŸ“ **[ìš”ì²­ 3] ì‚¬ìš© ì˜ˆì‹œ** âœ…

### ì˜ˆì‹œ 1: ë¬¸í•­ í•´ì„¤ ìƒì„±

```typescript
// API Route: /api/student/questions/[questionId]/explanation

import { callTextModel, buildQuestionExplanationPrompt } from '@/lib/ai';

export async function GET(request, { params }) {
  // 1. DBì—ì„œ question + answer ì¡°íšŒ
  const question = await supabase...;
  const answer = await supabase...;

  // 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
  const { systemPrompt, userPrompt } = buildQuestionExplanationPrompt({
    questionType: question.type,
    questionText: question.content,
    choices: question.options,
    correctAnswer: question.correct_answer,
    studentAnswer: answer.answer,
    isCorrect: answer.is_correct,
  });

  // 3. AI í˜¸ì¶œ
  const result = await callTextModel({
    systemPrompt,
    userPrompt,
    temperature: 0.7,
    maxTokens: 1500,
  });

  // 4. ì—ëŸ¬ ì²˜ë¦¬
  if (!result.success) {
    return NextResponse.json({ error: result.error }, { status: 500 });
  }

  // 5. ì‘ë‹µ
  return NextResponse.json({
    explanation: result.data.content,
    usage: result.data.usage,
  });
}
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
"ì •ë‹µì€ 2ë²ˆ Parisì…ë‹ˆë‹¤.

ParisëŠ” í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì´ì ê°€ì¥ í° ë„ì‹œì…ë‹ˆë‹¤.

í•™ìƒì´ ì„ íƒí•œ 1ë²ˆ Londonì€ ì˜êµ­ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤.
France(í”„ë‘ìŠ¤)ì™€ England(ì˜êµ­)ë¥¼ í˜¼ë™í•˜ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤.

íŒ: ìœ ëŸ½ ì£¼ìš” êµ­ê°€ì˜ ìˆ˜ë„ë¥¼ ì •ë¦¬í•´ì„œ ì•”ê¸°í•˜ì„¸ìš”."
```

---

### ì˜ˆì‹œ 2: ì‹œí—˜ ì•½ì  ë¶„ì„

```typescript
// API Route: /api/student/submissions/[submissionId]/analysis

import { callTextModel, buildWeaknessAnalysisPrompt } from '@/lib/ai';

export async function GET(request, { params }) {
  // 1. DBì—ì„œ submission + answers ì¡°íšŒ
  const submission = await supabase
    .from('submissions')
    .select(`*, exam(*), answers:submission_answers(*, question:questions(*))`)
    .eq('id', params.submissionId)
    .single();

  // 2. ì˜¤ë‹µë§Œ í•„í„°ë§
  const wrongAnswers = submission.answers.filter(a => !a.is_correct);

  // 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
  const { systemPrompt, userPrompt } = buildWeaknessAnalysisPrompt({
    examTitle: submission.exam.title,
    totalQuestions: submission.answers.length,
    correctCount: submission.answers.filter(a => a.is_correct).length,
    wrongCount: wrongAnswers.length,
    wrongQuestions: wrongAnswers.map(a => ({
      questionText: a.question.content,
      category: a.question.category,
      difficulty: a.question.difficulty,
      studentAnswer: a.answer,
      correctAnswer: a.question.correct_answer,
    })),
  });

  // 4. AI í˜¸ì¶œ
  const result = await callTextModel({
    systemPrompt,
    userPrompt,
    temperature: 0.8, // ì°½ì˜ì  ë¶„ì„
    maxTokens: 2500,
  });

  if (!result.success) {
    return NextResponse.json({ error: result.error }, { status: 500 });
  }

  // 5. DB ì €ì¥ (ì„ íƒ)
  await supabase.from('ai_analysis').insert({
    submission_id: params.submissionId,
    analysis_type: 'weakness',
    content: result.data.content,
    model: result.data.model,
    tokens: result.data.usage?.totalTokens,
  });

  // 6. ì‘ë‹µ
  return NextResponse.json({
    analysis: result.data.content,
    usage: result.data.usage,
  });
}
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
## ì „ì²´ ì„±ì  ìš”ì•½
- ì •ë‹µë¥ : 84% (38/45ë¬¸ì œ)
- ì „ì²´ì ìœ¼ë¡œ ì–‘í˜¸í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.

## ì£¼ìš” ì•½ì 
1. **ì–´íœ˜ ë¬¸ì œ** (7ë¬¸ì œ ì¤‘ 4ë¬¸ì œ ì˜¤ë‹µ)
   - ê³ ë‚œë„ ì–´íœ˜ ë¬¸ì œì—ì„œ ì•½ì ì„ ë³´ì…ë‹ˆë‹¤.
   - íŠ¹íˆ ì¶”ìƒì  ê°œë… ì–´íœ˜ì— ì·¨ì•½í•©ë‹ˆë‹¤.

2. **ë¹ˆì¹¸ ì¶”ë¡ ** (3ë¬¸ì œ ì˜¤ë‹µ)
   - ë¬¸ë§¥ íŒŒì•…ì€ ë˜ì§€ë§Œ ì •ë‹µ ì„ íƒì—ì„œ ì‹¤ìˆ˜

## í•™ìŠµ ì „ëµ
1. ê³ ë‚œë„ ì–´íœ˜ ë¦¬ìŠ¤íŠ¸ ë§¤ì¼ 20ê°œì”© ì•”ê¸°
2. ë¹ˆì¹¸ ë¬¸ì œëŠ” ì†Œê±°ë²• ì—°ìŠµ
3. ì‹œê°„ ë¶„ë°° ì—°ìŠµ (ì–´íœ˜ 5ë¶„ â†’ ë¹ˆì¹¸ 10ë¶„)
```

---

### ì˜ˆì‹œ 3: ì‹œí—˜ ì´ë¯¸ì§€ íŒŒì‹± (Vision)

```typescript
// API Route: /api/admin/exams/parse-image

import { callVisionModel, buildExamParsingPrompt } from '@/lib/ai';

export async function POST(request) {
  // 1. ì´ë¯¸ì§€ íŒŒì¼ ë°›ê¸°
  const formData = await request.formData();
  const file = formData.get('image') as File;
  
  // 2. Base64 ë³€í™˜
  const buffer = await file.arrayBuffer();
  const base64 = Buffer.from(buffer).toString('base64');

  // 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
  const { systemPrompt, userPrompt } = buildExamParsingPrompt({
    examType: 'multiple_choice',
    language: 'ko',
  });

  // 4. Vision AI í˜¸ì¶œ
  const result = await callVisionModel({
    systemPrompt,
    userPrompt,
    imageBase64: base64,
    temperature: 0.3, // ì •í™•ë„ ìš°ì„ 
    maxTokens: 4000,
  });

  if (!result.success) {
    return NextResponse.json({ error: result.error }, { status: 500 });
  }

  // 5. JSON íŒŒì‹±
  const parsed = JSON.parse(result.data.content);
  
  return NextResponse.json({
    questions: parsed.questions,
    count: parsed.questions.length,
    usage: result.data.usage,
  });
}
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```json
{
  "questions": [
    {
      "question_number": 1,
      "question_type": "mcq",
      "question_text": "What is the capital of France?",
      "choices": ["London", "Paris", "Berlin", "Madrid", "Rome"],
      "correct_answer": "2"
    }
  ]
}
```

---

## ğŸ“ **ìƒì„±ëœ íŒŒì¼ (5ê°œ)**

```
âœ… lib/ai/types.ts           (~150 lines) - íƒ€ì… ì •ì˜
âœ… lib/ai/openai.ts          (~200 lines) - OpenAI í´ë¼ì´ì–¸íŠ¸
âœ… lib/ai/prompts.ts         (~250 lines) - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
âœ… lib/ai/index.ts           (~30 lines)  - í†µí•© export
âœ… .env.example              - í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ
```

---

## ğŸ¯ **í•µì‹¬ ê¸°ëŠ¥**

### 1. ì•ˆì „í•œ í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬
```typescript
// ì‹±ê¸€í†¤ íŒ¨í„´
// í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
// ì„œë²„ ì „ìš© (í´ë¼ì´ì–¸íŠ¸ import ê¸ˆì§€)
```

### 2. Result íƒ€ì… íŒ¨í„´
```typescript
type AIResult<T> = 
  | { success: true; data: T }
  | { success: false; error: string; code?: string };

// throw ì•ˆ í•¨ â†’ ì•ˆì •ì  ì—ëŸ¬ ì²˜ë¦¬
```

### 3. ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸
```typescript
// í•¨ìˆ˜í˜• í…œí”Œë¦¿
// íŒŒë¼ë¯¸í„° íƒ€ì… ì •ì˜
// system + user ë¶„ë¦¬
```

---

## ğŸ“Š **ì‚¬ìš© íŒ¨í„´**

### íŒ¨í„´ 1: ê¸°ë³¸ ì‚¬ìš©
```typescript
const { systemPrompt, userPrompt } = buildQuestionExplanationPrompt(params);
const result = await callTextModel({ systemPrompt, userPrompt });

if (!result.success) {
  console.error(result.error);
  return fallback;
}

return result.data.content;
```

### íŒ¨í„´ 2: ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ìˆœì°¨
```typescript
const weakness = await callTextModel(buildWeaknessAnalysisPrompt(...));
const studyPlan = await callTextModel(buildStudyPlanPrompt(...));
const similar = await callTextModel(buildSimilarQuestionPrompt(...));
```

### íŒ¨í„´ 3: ë³‘ë ¬ ì²˜ë¦¬
```typescript
const promises = questions.map(q => 
  callTextModel(buildQuestionExplanationPrompt(q))
);
const results = await Promise.all(promises);
```

---

## âš ï¸ **ì£¼ì˜ì‚¬í•­**

### 1. í™˜ê²½ ë³€ìˆ˜ í•„ìˆ˜
```bash
OPENAI_API_KEY=sk-...
OPENAI_MODEL_TEXT=gpt-4o-mini
OPENAI_MODEL_VISION=gpt-4o
```

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
npm install openai
```

### 3. ì„œë²„ ì „ìš©
```typescript
// âŒ í´ë¼ì´ì–¸íŠ¸ ì»´í¬ë„ŒíŠ¸ì—ì„œ import ê¸ˆì§€
import { callTextModel } from '@/lib/ai'; // ì—ëŸ¬!

// âœ… API Routeì—ì„œë§Œ ì‚¬ìš©
// app/api/...
```

### 4. ì—ëŸ¬ ì²˜ë¦¬
```typescript
// í•­ìƒ result.success ì²´í¬
if (!result.success) {
  // fallback ì²˜ë¦¬
}
```

---

## ğŸ’° **ë¹„ìš© ìµœì í™”**

### 1. ëª¨ë¸ ì„ íƒ
```typescript
// ê°„ë‹¨í•œ ì‘ì—…: gpt-4o-mini (ì €ë ´)
model: 'gpt-4o-mini'

// ë³µì¡í•œ ì‘ì—…: gpt-4o (ê³ í’ˆì§ˆ)
model: 'gpt-4o'
```

### 2. ìºì‹±
```typescript
// Redis ë˜ëŠ” DBì— ê²°ê³¼ ìºì‹±
const cached = await redis.get(`explanation:${questionId}`);
if (cached) return cached;
```

### 3. ë°°ì¹˜ ì²˜ë¦¬
```typescript
// ì—¬ëŸ¬ ë¬¸ì œë¥¼ í•œ ë²ˆì— ìš”ì²­
// 3ë²ˆ í˜¸ì¶œ â†’ 1ë²ˆ í˜¸ì¶œ (í† í° ì ˆì•½)
```

---

## ğŸš€ **ë‹¤ìŒ ë‹¨ê³„ (Stage 4-2)**

### ì‹¤ì œ API ì—°ë™
1. âœ… ë¬¸í•­ í•´ì„¤ API êµ¬í˜„
2. âœ… ì•½ì  ë¶„ì„ API êµ¬í˜„
3. âœ… í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™

### ì¶”ê°€ í”„ë¡¬í”„íŠ¸
1. ìœ ì‚¬ ë¬¸ì œ ìƒì„±
2. í•™ìŠµ ê³„íš ìˆ˜ë¦½
3. ë¬¸ì œ ë‚œì´ë„ ë¶„ì„

### ì„±ëŠ¥ ê°œì„ 
1. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
2. ìºì‹± ì „ëµ
3. í† í° ìµœì í™”

---

## âœ… **Stage 4-1 ì™„ë£Œ!**

**ì™„ë£Œ í•­ëª©:**
- âœ… OpenAI SDK ì„ íƒ (ì•ˆì „í•˜ê³  í‘œì¤€ì )
- âœ… íŒŒì¼ êµ¬ì¡° ì„¤ê³„ (types, openai, prompts, index)
- âœ… callTextModel / callVisionModel êµ¬í˜„
- âœ… 3ê°œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬í˜„
- âœ… Result íƒ€ì… íŒ¨í„´ ì ìš©
- âœ… ì—ëŸ¬ ì²˜ë¦¬ + ë¡œê¹…
- âœ… ì‚¬ìš© ì˜ˆì‹œ 3ê°œ ì‘ì„±
- âœ… í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

**ì¤€ë¹„ ì™„ë£Œ!** ğŸ‰

ì´ì œ AI ê¸°ëŠ¥ì„ ì‰½ê²Œ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```typescript
import { callTextModel, buildQuestionExplanationPrompt } from '@/lib/ai';

// 3ì¤„ë¡œ AI í•´ì„¤ ìƒì„±
const prompts = buildQuestionExplanationPrompt(params);
const result = await callTextModel(prompts);
const explanation = result.data.content;
```
